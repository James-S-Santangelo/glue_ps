{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac03c52-ca6d-4447-a260-2d06f54d69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e98b4-bc5e-4638-84dc-c9a47b07c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_minor_dict = {chrom: {} for chrom in snakemake.params['chrom']}\n",
    "maf_prefix = snakemake.params[\"maf_prefix\"]\n",
    "\n",
    "for chrom in snakemake.params[\"chrom\"]:\n",
    "    glob_maf_path = f\"{maf_prefix}/allSamples/{chrom}/{chrom}_allSamples_snps.mafs.gz\"\n",
    "    glob_mafs = gzip.open(glob_maf_path,'rb').readlines()\n",
    "\n",
    "    for i, l in enumerate(glob_mafs):\n",
    "        if i != 0:\n",
    "            sl = l.strip().split(b\"\\t\")\n",
    "            pos = sl[1].decode(\"utf-8\")\n",
    "            REF = sl[2]\n",
    "            ALT = sl[3]\n",
    "            major_minor_dict[chrom][pos] = [REF, ALT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e704e-51e4-4b50-b8e7-ccec18674c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_positions(city, habitat):\n",
    "    pos_index_dict = {chrom: {} for chrom in snakemake.params['chrom']}\n",
    "    for chrom in snakemake.params[\"chrom\"]:\n",
    "        pos_path = f\"{maf_prefix}/byCity/{city}/{chrom}/{city}_{habitat}_{chrom}_snps.pos.gz\"\n",
    "        with gzip.open(pos_path,'rb') as pos:\n",
    "            lines = pos.readlines() \n",
    "            for i, l in enumerate(lines):\n",
    "                if i != 0:\n",
    "                    sl = l.strip().split(b\"\\t\")\n",
    "                    pos = sl[1].decode('utf-8')\n",
    "                    pos_index_dict[chrom][pos] = i\n",
    "    return pos_index_dict\n",
    "\n",
    "city_pos_index_dict = {city: {hab: [] for hab in snakemake.params[\"habitats\"]} for city in snakemake.params[\"cities\"]}\n",
    "for city in tqdm.tqdm(snakemake.params[\"cities\"]):\n",
    "    for hab in snakemake.params[\"habitats\"]:\n",
    "        city_pos_index_dict[city][hab] = extract_positions(city, hab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c3486-bac3-4289-b415-35dc191b329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dict = {city: {hab: {chrom: [] for chrom in snakemake.params[\"chrom\"]} for hab in snakemake.params[\"habitats\"]} for city in snakemake.params[\"cities\"]}\n",
    "\n",
    "def map_global_site_to_city_pos_indices(city, hab):\n",
    "    index_mapping_dict = {chrom: {} for chrom in snakemake.params['chrom']}\n",
    "    for chrom in snakemake.params[\"chrom\"]:\n",
    "        for g_pos in major_minor_dict[chrom].keys():\n",
    "            try:\n",
    "                pos_idx = city_pos_index_dict[city][hab][chrom][g_pos]\n",
    "                index_mapping_dict[chrom][g_pos] = pos_idx\n",
    "            except KeyError:\n",
    "                # print(f\"{chrom}: {gp} missing from {hab} habitat in {city}\")\n",
    "                missing_dict[city][hab][chrom].append(g_pos)\n",
    "    return index_mapping_dict\n",
    "\n",
    "city_index_mapping_dict = {city: {hab: [] for hab in snakemake.params[\"habitats\"]} for city in snakemake.params[\"cities\"]}\n",
    "for city in tqdm.tqdm(snakemake.params[\"cities\"]):\n",
    "    for hab in snakemake.params[\"habitats\"]:\n",
    "        city_index_mapping_dict[city][hab] = map_global_site_to_city_pos_indices(city, hab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0c5b3-a9e5-4509-afdb-e5eec1a25226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_missing_site_dict = {chrom: set() for chrom in snakemake.params['chrom']}\n",
    "\n",
    "for city in tqdm.tqdm(snakemake.params[\"cities\"]):\n",
    "    for hab in snakemake.params[\"habitats\"]:\n",
    "        for chrom in snakemake.params[\"chrom\"]:\n",
    "            combined_missing_site_dict[chrom].update(missing_dict[city][hab][chrom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa53f16-057b-4adf-bb1a-b3e4f09be5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prefix = snakemake.params[\"out_prefix\"]\n",
    "\n",
    "def write_alleleCounts_byCity(city):\n",
    "    outpath = f\"{out_prefix}/{city}\"\n",
    "\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "\n",
    "    outfile = f\"{outpath}/{city}.geno\"\n",
    "    with open(outfile, \"w\") as fout:\n",
    "        for chrom in snakemake.params[\"chrom\"]:\n",
    "            urb_mafs_path = f\"{maf_prefix}/byCity/{city}/{chrom}/{city}_urban_{chrom}_snps.mafs.gz\"\n",
    "            rur_mafs_path = f\"{maf_prefix}/byCity/{city}/{chrom}/{city}_rural_{chrom}_snps.mafs.gz\"\n",
    "            \n",
    "            urban_mafs = gzip.open(urb_mafs_path,'rb').readlines()\n",
    "            rural_mafs = gzip.open(rur_mafs_path,'rb').readlines()\n",
    "            \n",
    "            for g_pos in major_minor_dict[chrom].keys():\n",
    "                if g_pos in combined_missing_site_dict[chrom]:\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        urban_idx = city_pos_index_dict[city][\"urban\"][chrom].get(g_pos, None)\n",
    "                        rural_idx = city_pos_index_dict[city][\"rural\"][chrom].get(g_pos, None)\n",
    "    \n",
    "                        urban_site = urban_mafs[urban_idx].strip().split(b\"\\t\")\n",
    "                        rural_site = rural_mafs[rural_idx].strip().split(b\"\\t\")\n",
    "                        \n",
    "                        urban_af = float(urban_site[6].decode(\"UTF-8\"))\n",
    "                        rural_af = float(rural_site[6].decode(\"UTF-8\"))\n",
    "                        urban_nInd = int(urban_site[7].decode(\"UTF-8\"))\n",
    "                        rural_nInd = int(rural_site[7].decode(\"UTF-8\"))\n",
    "                        \n",
    "                        urban_alt_count = round(urban_af * urban_nInd * 2)\n",
    "                        urban_ref_count = (urban_nInd * 2) - urban_alt_count\n",
    "                        rural_alt_count = round(rural_af * rural_nInd * 2)\n",
    "                        rural_ref_count = (rural_nInd * 2) - rural_alt_count\n",
    "    \n",
    "                        # print(f\"At {chrom}:{g_pos}\")\n",
    "                        # print(f\"Urban: ALT AF of {urban_af} resulting in {urban_alt_count} ALT alleles and {urban_ref_count} REF alleles\")\n",
    "                        # print(f\"Rural: ALT AF of {rural_af} resulting in {rural_alt_count} ALT alleles and {rural_ref_count} REF alleles\")\n",
    "                        # print(\"========================\")\n",
    "                        fout.write(f\"{urban_ref_count} {urban_alt_count} {rural_ref_count} {rural_alt_count}\\n\")\n",
    "                    except IndexError:\n",
    "                        print(f\"{chrom}: {g_pos}\")\n",
    "                        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4756d16-0774-4f54-82e4-e514819e60be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for city in tqdm.tqdm(snakemake.params[\"cities\"]):\n",
    "    write_alleleCounts_byCity(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36bc651-ecf3-473e-8ec8-b3ebc44d3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cont_file in snakemake.output[\"perCity_cont\"]:\n",
    "    with open(cont_file, \"w\") as fout:\n",
    "        fout.write(\"1 -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ce42e-181a-422f-b358-e516b3f3e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### with open(snakemake.output[\"site_order\"], \"w\") as fout:\n",
    "    for chrom in snakemake.params[\"chrom\"]:\n",
    "        for gp in major_minor_dict[chrom].keys():\n",
    "            if gp in combined_missing_site_dict[chrom]:\n",
    "                pass\n",
    "            else:\n",
    "                fout.write(f\"{chrom}\\t{gp}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e61bb2-14de-4626-a422-fd3c291084c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(snakemake.output[\"miss\"], \"w\") as fout:\n",
    "    for city in tqdm.tqdm(snakemake.params[\"cities\"]):\n",
    "        for hab in snakemake.params[\"habitats\"]:\n",
    "            for chrom in snakemake.params[\"chrom\"]:\n",
    "                for pos in missing_dict[city][hab][chrom]:\n",
    "                    # print(f\"{chrom}: {pos} missing from {hab} habitat in {city}\")\n",
    "                    fout.write(f\"{city}\\t{hab}\\t{chrom}\\t{pos}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
